{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unleash the Ray - Grid Search\n",
    "\n",
    "Let's revisit our grid search example but now with Ray\n",
    "\n",
    "A lot of this code is going to be familiar as we already had our pipeline wraped in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dependencies we have already seen...\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dependencies import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-06 15:15:11,425\tINFO services.py:1164 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'node_ip_address': '192.168.2.140',\n 'raylet_ip_address': '192.168.2.140',\n 'redis_address': '192.168.2.140:62656',\n 'object_store_address': '/tmp/ray/session_2020-11-06_15-15-10_731830_11885/sockets/plasma_store',\n 'raylet_socket_name': '/tmp/ray/session_2020-11-06_15-15-10_731830_11885/sockets/raylet',\n 'webui_url': '127.0.0.1:8265',\n 'session_dir': '/tmp/ray/session_2020-11-06_15-15-10_731830_11885',\n 'metrics_export_port': 64493}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init(num_cpus=10, num_gpus=0, include_dashboard=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initialisation the [Ray Dashboard](https://docs.ray.io/en/master/ray-dashboard.html) is available on the **webui_url** port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup some raytune compatible training code\n",
    "\n",
    "Very similar to before except now we have an end-to-end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# differences from what we've seen before, this is an end to end training function\n",
    "# where we are loading the dataset running our complete train and test loop whilst\n",
    "# \n",
    "def e2e_simple_training(config):\n",
    "    \n",
    "    #threadsafe\n",
    "    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    \n",
    "    # chose your CV strategy\n",
    "    splitter = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    # run k fold training and testing\n",
    "    f1_scores = [] # keep hold of all individual scores\n",
    "    for train_ind, test_ind in splitter.split(X, y):\n",
    "        pipeline = make_pipeline(RobustScaler(),\n",
    "                                  RandomForestClassifier(random_state=42))\n",
    "\n",
    "        pipeline.set_params(**config)\n",
    "        pipeline.fit(X[train_ind], y[train_ind])\n",
    "        \n",
    "        y_pred = pipeline.predict(X[test_ind])\n",
    "        \n",
    "        f1_scores.append(f1_score(y_pred, y[test_ind]))\n",
    "    \n",
    "    # use tunes reporter\n",
    "    tune.track.log(mean_f1_score=np.array(f1_scores).mean(),\n",
    "                std_f1_score=np.array(f1_scores).std(),\n",
    "                # and we can actually add any metrics we like\n",
    "                done=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we had a param grid like this\n",
    "\n",
    "```\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [1,5,15,50,100],\n",
    "    'randomforestclassifier__criterion': ['gini', 'entropy'],\n",
    "    'randomforestclassifier__bootstrap': [True, False]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO convert this to a set of ray search spaces\n",
    "\n",
    "The Ray config object is freeform, we imprint our own structure.\n",
    "\n",
    "However, tunable parameters need to be represented by tune distribution object >> [read the docs](https://docs.ray.io/en/latest/tune/api_docs/grid_random.html?highlight=tune.grid#random-distributions-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_tuning_config = {\n",
    "    'randomforestclassifier__n_estimators': tune.grid_search([1,5,15,50,100])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "                e2e_simple_training,\n",
    "                config=ray_tuning_config,\n",
    "                resources_per_trial=dict(cpu=1, gpu=0),\n",
    "                local_dir=\"~/ray_results/grid_search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis.dataframe()\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best config: \", analysis.get_best_config(metric=\"mean_f1_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def plot_some_tune_results(df):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16,6))\n",
    "    x = np.linspace(0.85, 1.0, 100)\n",
    "\n",
    "    n_estimators = df['config/randomforestclassifier__n_estimators'].values.tolist()\n",
    "\n",
    "    lines = []\n",
    "    for mu, sigma in zip(df['mean_f1_score'], df['std_f1_score']):\n",
    "        pdf = norm.pdf(x, mu, sigma)\n",
    "        line, = ax.plot(x, pdf, alpha=0.6)\n",
    "        ax.axvline(mu, color=line.get_color())\n",
    "        ax.text(mu, pdf.max(), f\"{mu:.3f}\", color=line.get_color(), fontsize=14)\n",
    "        lines.append(line)\n",
    "\n",
    "    plt.legend(handles=lines, labels=n_estimators, title=\"n estimators\")\n",
    "    ax.set_title(f\"Average F1 Scores\")\n",
    "    \n",
    "plot_some_tune_results(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Really increase the size of the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 6D search space - 960 combinations - 4800 calls to fit\n",
    "#\n",
    "\n",
    "ray_tuning_config = {\n",
    "    'randomforestclassifier__n_estimators': tune.grid_search([1,5,15,50,100]),\n",
    "    'randomforestclassifier__criterion': tune.grid_search(['gini', 'entropy']),\n",
    "    'randomforestclassifier__max_features': tune.grid_search(['auto', 'sqrt', 'log2']),\n",
    "#     'randomforestclassifier__bootstrap': tune.grid_search([True, False]),\n",
    "#     'randomforestclassifier__min_samples_leaf': tune.grid_search([1,2,3,4]),\n",
    "    'randomforestclassifier__min_samples_split': tune.grid_search([3,4,5,6])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "                e2e_simple_training,\n",
    "                config=ray_tuning_config,\n",
    "                resources_per_trial=dict(cpu=1, gpu=0)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "print(\"Best config: \")\n",
    "pprint(analysis.get_best_config(metric=\"mean_f1_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis.dataframe()\n",
    "top_n_df = df.nlargest(10, \"mean_f1_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_some_tune_results(top_n_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "%tensorboard --logdir \"~/ray_results/grid_search\"\n",
    "notebook.display(height=1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you are all done, shutdown Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}